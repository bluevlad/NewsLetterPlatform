"""
AllergyInsight ë°ì´í„° ìˆ˜ì§‘ê¸°
AllergyInsight Backend API v2.0.0 í˜¸ì¶œ

API Endpoints:
  - POST /api/auth/simple/login â†’ JWT í† í° íšë“
  - GET  /api/admin/news â†’ ë‰´ìŠ¤ ëª©ë¡ (Bearer ì¸ì¦)
  - GET  /api/admin/news/stats â†’ ë‰´ìŠ¤ í†µê³„ (Bearer ì¸ì¦)
  - GET  /api/papers â†’ ë…¼ë¬¸ ëª©ë¡ (ê³µê°œ)
"""

import logging
from datetime import datetime, timezone
from typing import Any, Dict, Optional

import httpx

from ...common.utils import retry_async
from ...config import settings

logger = logging.getLogger(__name__)

API_TIMEOUT = 60.0


class AllergyInsightCollector:
    """AllergyInsight API ë°ì´í„° ìˆ˜ì§‘ê¸° (v2.0.0)"""

    def __init__(self, api_base_url: str = None):
        self.api_base_url = (
            api_base_url or settings.allergy_insight_api_url
        ).rstrip("/")
        self._token: Optional[str] = None

    async def _login(self) -> str:
        """ê´€ë¦¬ì ë¡œê·¸ì¸ìœ¼ë¡œ JWT í† í° íšë“"""
        url = f"{self.api_base_url}/api/auth/simple/login"
        payload = {
            "name": settings.allergy_insight_admin_name,
            "phone": settings.allergy_insight_admin_phone,
            "access_pin": settings.allergy_insight_admin_pin,
        }

        async def _request():
            async with httpx.AsyncClient(timeout=API_TIMEOUT) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                data = response.json()
                return data["access_token"]

        token = await retry_async(_request)
        self._token = token
        logger.info("AllergyInsight JWT í† í° íšë“ ì™„ë£Œ")
        return token

    async def _get(self, path: str, auth_required: bool = True) -> Any:
        """API GET ìš”ì²­ (3íšŒ ì¬ì‹œë„)"""
        url = f"{self.api_base_url}{path}"
        headers = {}
        if auth_required and self._token:
            headers["Authorization"] = f"Bearer {self._token}"

        async def _request():
            async with httpx.AsyncClient(timeout=API_TIMEOUT) as client:
                response = await client.get(url, headers=headers)
                response.raise_for_status()
                return response.json()

        return await retry_async(_request)

    async def _collect_news(self, page_size: int = 100) -> list[dict]:
        """ë‰´ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ - GET /api/admin/news"""
        data = await self._get(f"/api/admin/news?page=1&page_size={page_size}")
        return data.get("items", [])

    async def _collect_news_stats(self) -> dict:
        """ë‰´ìŠ¤ í†µê³„ ìˆ˜ì§‘ - GET /api/admin/news/stats"""
        return await self._get("/api/admin/news/stats")

    async def _collect_papers(self, page_size: int = 100) -> list[dict]:
        """ë…¼ë¬¸ ëª©ë¡ ìˆ˜ì§‘ - GET /api/papers (ê³µê°œ API)"""
        data = await self._get(
            f"/api/papers?page=1&page_size={page_size}",
            auth_required=False,
        )
        return data.get("items", [])

    def _transform_news(self, raw_items: list[dict]) -> list[dict]:
        """v2.0.0 ë‰´ìŠ¤ ì•„ì´í…œ â†’ daily_report top_news í¬ë§· ë³€í™˜"""
        result = []
        for item in raw_items:
            result.append({
                "id": item.get("id"),
                "content_type": "ë‰´ìŠ¤",
                "title": item.get("title", ""),
                "description": item.get("description", ""),
                "link": item.get("url", ""),
                "original_link": item.get("url", ""),
                "pub_date": item.get("published_at", ""),
                "source": item.get("source", ""),
                "keyword": item.get("search_keyword", ""),
                "category": item.get("category") or "ê¸°íƒ€",
                "summary": item.get("summary"),
                "importance_score": item.get("importance_score"),
                "company": item.get("company_name"),
            })
        return result

    def _transform_papers(self, raw_items: list[dict]) -> list[dict]:
        """v2.0.0 ë…¼ë¬¸ ì•„ì´í…œ â†’ daily_report papers í¬ë§· ë³€í™˜"""
        result = []
        for item in raw_items:
            result.append({
                "id": item.get("id"),
                "content_type": "ë…¼ë¬¸",
                "title": item.get("title", ""),
                "link": item.get("url", ""),
                "journal": item.get("journal", ""),
                "pmid": item.get("pmid"),
                "doi": item.get("doi"),
                "authors": item.get("authors", ""),
                "pub_date": str(item.get("year", "")),
                "abstract": item.get("abstract", ""),
            })
        return result

    def _build_news_groups(self, news_items: list[dict]) -> list[dict]:
        """ë‰´ìŠ¤ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í•‘"""
        from collections import defaultdict

        by_category = defaultdict(list)
        for item in news_items:
            cat = item.get("category") or "ê¸°íƒ€"
            by_category[cat].append(item)

        category_config = {
            "ì„ìƒ/ì¹˜ë£Œ": {"icon": "ğŸ¥", "color": "#2e7d32", "bg_color": "#e8f5e9"},
            "ì—°êµ¬/í•™ìˆ ": {"icon": "ğŸ”¬", "color": "#1565c0", "bg_color": "#e3f2fd"},
            "ìƒí™œ/ê´€ë¦¬": {"icon": "ğŸ ", "color": "#ef6c00", "bg_color": "#fff3e0"},
            "ì‚°ì—…/ê·œì œ": {"icon": "ğŸ¢", "color": "#6a1b9a", "bg_color": "#f3e5f5"},
            "ê¸°íƒ€": {"icon": "ğŸ“°", "color": "#757575", "bg_color": "#fafafa"},
        }

        groups = []
        for cat, items in by_category.items():
            cfg = category_config.get(cat, category_config["ê¸°íƒ€"])
            groups.append({
                "title": cat,
                "icon": cfg["icon"],
                "color": cfg["color"],
                "border_color": cfg["color"],
                "bg_color": cfg["bg_color"],
                "entries": [
                    {"article": item, "category_name": cat}
                    for item in items
                ],
                "total_count": len(items),
            })
        return groups

    def _build_company_news(self, news_items: list[dict]) -> list[dict]:
        """ë‰´ìŠ¤ë¥¼ ê¸°ì—…ë³„ë¡œ ê·¸ë£¹í•‘"""
        from collections import defaultdict

        by_company = defaultdict(list)
        for item in news_items:
            company = item.get("company")
            if company:
                by_company[company].append(item)

        result = []
        for name, items in by_company.items():
            result.append({
                "name": name,
                "type": "main",
                "trend_summary": "",
                "articles": [
                    {
                        "title": item["title"],
                        "link": item["link"],
                        "source": item.get("source", ""),
                        "pub_date": item.get("pub_date", ""),
                    }
                    for item in items
                ],
            })
        return result

    async def collect_daily_report(self) -> Dict:
        """ì¼ì¼ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ â€” ë¡œê·¸ì¸ í›„ ë‰´ìŠ¤+ë…¼ë¬¸+í†µê³„ ì¡°í•©"""
        try:
            # 1. JWT í† í° íšë“
            await self._login()

            # 2. ë°ì´í„° ìˆ˜ì§‘
            raw_news = await self._collect_news()
            raw_stats = await self._collect_news_stats()
            raw_papers = await self._collect_papers()

            # 3. í¬ë§· ë³€í™˜
            news_items = self._transform_news(raw_news)
            paper_items = self._transform_papers(raw_papers)

            # ì¤‘ìš”ë„ ìˆœ ì •ë ¬ (top_news)
            scored = [n for n in news_items if n.get("importance_score")]
            unscored = [n for n in news_items if not n.get("importance_score")]
            scored.sort(
                key=lambda x: x.get("importance_score", 0) or 0,
                reverse=True,
            )
            top_news = scored + unscored

            # ë‰´ìŠ¤ ê·¸ë£¹ (ì¹´í…Œê³ ë¦¬ë³„)
            news_groups = self._build_news_groups(news_items)

            # ê¸°ì—… ë‰´ìŠ¤
            company_news = self._build_company_news(news_items)

            now = datetime.now(timezone.utc).isoformat()

            report = {
                "report_date": now,
                "generated_at": now,
                "top_news": top_news[:20],
                "news_groups": news_groups,
                "papers": paper_items[:20],
                "company_news": company_news,
                "stats": {
                    "news_count": raw_stats.get("total_news", len(news_items)),
                    "paper_count": len(paper_items),
                    "company_count": len(company_news),
                    "total_count": (
                        raw_stats.get("total_news", len(news_items))
                        + len(paper_items)
                        + len(company_news)
                    ),
                    "trend_company_count": len(company_news),
                },
            }

            logger.info(
                f"AllergyInsight ì¼ì¼ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ: "
                f"ë‰´ìŠ¤ {len(news_items)}ê±´, ë…¼ë¬¸ {len(paper_items)}ê±´, "
                f"ê¸°ì—… {len(company_news)}ê±´"
            )
            return report

        except Exception as e:
            logger.error(f"AllergyInsight ì¼ì¼ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}

    async def collect_all(self) -> Dict[str, Any]:
        """ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""
        result = {}

        daily_report = await self.collect_daily_report()
        if daily_report:
            result["daily_report"] = daily_report

        logger.info(f"AllergyInsight ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {list(result.keys())}")
        return result
